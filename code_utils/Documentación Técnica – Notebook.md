# üìò Documentaci√≥n T√©cnica ‚Äì Notebook: NB_Ingest_TiendasON

**Autor:** Oscar Mosquera  
**Versi√≥n:** 1.1  
**Fecha:** 2025-10-09  
**Notebook objetivo:** `NB_Ingest_TiendasON`  

---

## 1. Identificaci√≥n

| Campo | Descripci√≥n |
|--------|--------------|
| **Nombre del Notebook** | `NB_Ingest_TiendasON` |
# üìò Documentaci√≥n T√©cnica ‚Äì Notebook: NB_Ingest_TiendasON

**Autor:** Oscar Mosquera  
**Versi√≥n:** 1.2  
**Fecha:** 2025-10-09  
**Notebook objetivo:** `NB_Ingest_TiendasON`  

---

## 1. Identificaci√≥n

| Campo | Descripci√≥n |
|--------|--------------|
| **Nombre del Notebook** | `NB_Ingest_TiendasON` |
| **M√≥dulo / Capa Medallion** | Ingestion / Bronze |
| **Workspace** | WS_Data_Engineering |
| **Lakehouse** | LH_TiendasOn |
| **Autor / Responsable** | Oscar Mosquera |
| **Versi√≥n** | 1.2 |
| **Fecha de creaci√≥n / √∫ltima modificaci√≥n** | 2025-10-09 |
| **Estado** | En revisi√≥n |

---

## 2. Prop√≥sito y alcance

- **Prop√≥sito:** Orquestar la extracci√≥n incremental de datos de tiendas desde fuentes SQL/OLTP hacia el Lakehouse, aplicando control de watermark, particionado por ventanas horarias y registros de auditor√≠a.
- **Alcance:** Este documento describe √∫nicamente `NB_Ingest_TiendasON`. Aunque el notebook utiliza utilidades y m√≥dulos compartidos (por ejemplo `db_utils`, `partition_utils`, `watermark_utils`, `sql_repository`), la documentaci√≥n se centra en la l√≥gica, entradas y ejecuci√≥n del notebook.
- **Salida principal:** Tablas delta en la zona `bronze` por tienda/plataforma.

---

## 3. Entradas y salidas

| Tipo | Recurso | Descripci√≥n |
|------|----------|--------------|
| **Entrada (Scheduler/Trigger)** | Scheduler / Pipeline trigger | Indica cu√°ndo ejecutar el notebook y par√°metros runtime (p.ej. `store_id`, `run_id`, `partition_window`, overrides). |
| **Entrada (Config)** | `config.py` / JSON externos / `get_schedules` | Par√°metros de conexi√≥n, artefactos y reglas de particionado. En este notebook la lista de programaciones se obtiene mediante `get_schedules(conn)` desde la base central y se filtra por `project` para determinar qu√© jobs ejecutar. |
| **Entrada (Secrets)** | Key Vault / Secret Store | Credenciales para conexiones a bases de datos y artefactos. |
| **Salida** | `lakehouse.bronze.*` | Tablas Delta destino (por dataset/plataforma) |
| **Log / Auditor√≠a** | Tabla `Ingest_Audit` / Log files | Estado, filas procesadas, duraci√≥n, errores |

---

## 4. Estructura t√©cnica y pasos clave

1. Inicializaci√≥n: carga de `config.py`, logger y utilidades (`db_utils`, `partition_utils`, `watermark_utils`, `sql_repository`).
2. Lectura de programaciones: invocar `get_schedules(central_conn)` para obtener el cat√°logo de jobs y filtrar por `project`.
3. Determinaci√≥n de la franja horaria y c√°lculo del bloque actual (usando `get_block_number_in_window`).
4. Para cada bloque/plataforma: resolver artefacto/linked service y obtener conexi√≥n desde `FabricConnectionManager` (a trav√©s de `ConnectionPool`).
5. Lectura incremental con watermark (si existe) o carga completa seg√∫n par√°metros.
6. Escritura a Delta por partici√≥n y actualizaci√≥n del watermark en tabla de tracking.
7. Registro en `Ingest_Audit`, liberaci√≥n de recursos y metrics.

### Notas importantes
- El notebook consulta `get_schedules` para decidir qu√© programas/jobs ejecutar. `get_schedules` retorna metadata (project, source_type, table_name, schedule_time, interval, etc.) que el notebook filtra por `project` y `source_type`.
- El notebook usa particionado por bloque horario; cuando `get_block_number_in_window` devuelve `None` se omite el procesamiento para ese run.
- El manejo correcto de conexiones y liberaci√≥n es cr√≠tico: usa `acquire_connection_context` o aseg√∫rate de `release_connection` en finally.

---

## 5. Ejemplo de resultado de `get_schedules`

Payload m√≠nimo esperado (ejemplo):

```json
[
  {
    "project": "TiendasOn",
    "source_type": "platform",
    "platform_name": "TryController",
    "table_name": "DevicesRoutesTokenSession",
    "schedule_time": "00:00",
    "interval": "hourly",
    "enabled": true
  },
  {
    "project": "TryController",
    "source_type": "database",
    "platform_name": null,
    "table_name": "Loans",
    "schedule_time": "11:00",
    "interval": "daily",
    "enabled": true
  }
]
```

Columnas relevantes que el notebook utiliza: `project`, `source_type`, `table_name`, `schedule_time`, `enabled`, `platform_name`.

---

## 5.1 Validaci√≥n del payload de `get_schedules`

Es recomendable validar el payload que retorna `get_schedules` antes de usarlo en producci√≥n. A continuaci√≥n se especifica el schema esperado y ejemplos de estructuras para `keys_info` y `partition_info`.

- Columnas m√≠nimas obligatorias (DataFrame):
  - `tables_source_id` (int)
  - `project` (str)
  - `source_type` (str) - valores esperados: `platform`, `database`, etc.
  - `table_name` (str)
  - `execution_time` (HH:MM o HH:MM:SS)
  - `status` (0/1)

- Columnas opcionales (√∫tiles):
  - `keys_info`: lista de objetos [{"field_name": "id", "is_primary_key": 1}, ...]
  - `partition_info`: lista de objetos [{"field_name": "created_at", "type_field": "datetime"}, ...]
  - `is_incremental` (0/1 o true/false)
  - `platform_name`, `schem`, `enabled`, `interval`

Ejemplo de `keys_info` y `partition_info`:

```python
keys_info = [
    {"field_name": "id", "is_primary_key": 1},
    {"field_name": "store_id", "is_primary_key": 0},
]

partition_info = [
    {"field_name": "CreatedTS", "type_field": "datetime"},
]
```

Snippet para validar desde el notebook usando el validador incluido en el repo (`validate_get_schedules.py`):

```python
from validate_get_schedules import validate_schedules_from_conn

# conn: conexi√≥n/engine que acepta get_schedules
ok, messages, df_schedules = validate_schedules_from_conn(conn, allow_import=True, strict=True)
if not ok:
    log("Payload de get_schedules inv√°lido:\n" + "\n".join(messages), level="error")
    raise RuntimeError("Validaci√≥n de get_schedules fall√≥; revisar mensajes de log.")
else:
    log("Validaci√≥n de payload OK", level="info")

```

Notas:
- `allow_import=True` permite que el helper importe `ingestion_utils.get_schedules` directamente; √∫salo con cuidado en entornos donde la importaci√≥n pueda cargar dependencias pesadas.
- `strict=True` activa validaciones adicionales que verifican la estructura de `keys_info` y `partition_info` por fila.


## 6. Par√°metros de configuraci√≥n (ejemplos)

```python
# config.py (extracto)
NOTEBOOK_NAME = "NB_Ingest_TiendasON"
WORKSPACE_ID = "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
ARTIFACT_SQL = "DB_Engineering"
POOL_MAX_CONNECTIONS = 10
PARTITION_TOTAL_BLOCKS = 4
PARTITION_WINDOW_START = 0   # 00:00
PARTITION_WINDOW_END = 8     # 08:00
WATERMARK_TABLE = "ingest.watermarks"
LOG_TABLE = "DataOn.LastWatermarkState"
```

---

## 7. Snippets de uso y ejemplos pr√°cticos

### 7.1 Leer programaciones y filtrar por proyecto

```python
# central_db_conn: conexi√≥n a la base central con la tabla de schedules
from sql_repository import get_schedules
 
df_schedules = get_schedules(central_db_conn)
# filtrar por project y tipo
df_pf_TiendasOn = df_schedules[(df_schedules["source_type"].str.lower() == "platform") &
                                (df_schedules["project"] == "TiendasOn")]
```

### 7.2 Determinar bloque horario y procesar

```python
block_number = get_block_number_in_window(PARTITION_TOTAL_BLOCKS, PARTITION_WINDOW_START, PARTITION_WINDOW_END)
if block_number is None:
    log("Fuera de la franja, no se procesa este run", level="info")
else:
    # procesar solo los registros/plataformas de este bloque
    df_block_conns = get_block(df_total, block_number, PARTITION_TOTAL_BLOCKS)
```

### 7.3 Adquirir conexi√≥n segura con timeout

```python
with conn_mgr_fabric.connection_pool.acquire_connection_context(f"sql_{ARTIFACT_SQL}", lambda: get_db_connection_fabricsqldatabase2(ARTIFACT_SQL, WORKSPACE_ID, notebookutils), wait_for=30) as conn:
    if conn is None:
        log("No hay conexi√≥n disponible, abortando run", level="error")
    else:
        # leer / procesar
        df = fetch_all_data(conn, query)
```

---

## 8. Troubleshooting (problemas comunes)

- Error: `No se pudo obtener conexi√≥n ... Pool lleno.`
  - Causa: pool alcanz√≥ `max_connections` y no hay conexiones libres.
  - Acciones: aumentar `POOL_MAX_CONNECTIONS`, asegurar `release_connection` en finally/context manager, reducir concurrencia, revisar que `connection_key` es √∫nico por artifact.

- Error: `get_block_number_in_window` devuelve `None` inesperadamente
  - Causa: hora actual fuera de la franja configurada o franja mal configurada (p. ej. start==end se interpreta como vac√≠a).
  - Acciones: verificar `PARTITION_WINDOW_START`/`END`, zona horaria y uso de `datetime.now() - timedelta(hours=offset)` si aplica; considerar cambiar la interpretaci√≥n de start==end a 24h si lo deseas.

- Error: `KeyError` o columnas faltantes al aplicar `get_block` / `get_sql_table_schema`
  - Causa: mismatch entre metadata de `get_schedules` y la tabla real.
  - Acciones: inspeccionar `df_schedules` y `df_schema`, loggear columnas y ejemplos de filas.

---

## 9. Observaciones y pr√≥ximos pasos

- A√±adir m√©tricas de pool y trazabilidad por conexi√≥n (logs peri√≥dicos de `pool.get_stats()`).
- A√±adir tests unitarios para `get_block_number_in_window` y pruebas de integraci√≥n para la l√≥gica de conexi√≥n y `get_schedules`.
- Documentar el payload del scheduler y la forma en que pipeline pasa `run_id`, `store_id` y `overrides` al notebook.

---

**Fin de la documentaci√≥n actualizada para `NB_Ingest_TiendasON`.**
